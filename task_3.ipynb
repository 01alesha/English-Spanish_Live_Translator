{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417b0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)  [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)  [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, None, 128)            294912    ['encoder_input[0][0]']       \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, None, 128)            556800    ['decoder_input[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, None, 256),          394240    ['embedding_2[0][0]']         \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, None, 256),          394240    ['embedding_3[0][0]',         \n",
      "                              (None, 256),                           'lstm_2[0][1]',              \n",
      "                              (None, 256)]                           'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 256)            0         ['lstm_3[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, None, 512)            0         ['lstm_3[0][0]',              \n",
      " )                                                                   'attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 4350)           2231550   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3871742 (14.77 MB)\n",
      "Trainable params: 3871742 (14.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 55s 213ms/step - loss: 2.3828 - accuracy: 0.6722 - val_loss: 2.0565 - val_accuracy: 0.7004\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 1.5870 - accuracy: 0.7559 - val_loss: 1.8502 - val_accuracy: 0.7324\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 1.3714 - accuracy: 0.7822 - val_loss: 1.7454 - val_accuracy: 0.7498\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 55s 219ms/step - loss: 1.2136 - accuracy: 0.7980 - val_loss: 1.6920 - val_accuracy: 0.7588\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 57s 228ms/step - loss: 1.0710 - accuracy: 0.8101 - val_loss: 1.6536 - val_accuracy: 0.7668\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.9374 - accuracy: 0.8228 - val_loss: 1.6269 - val_accuracy: 0.7744\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 56s 226ms/step - loss: 0.8165 - accuracy: 0.8352 - val_loss: 1.6311 - val_accuracy: 0.7812\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 63s 252ms/step - loss: 0.7063 - accuracy: 0.8482 - val_loss: 1.6255 - val_accuracy: 0.7875\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 52s 210ms/step - loss: 0.6086 - accuracy: 0.8614 - val_loss: 1.6466 - val_accuracy: 0.7859\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 53s 210ms/step - loss: 0.5243 - accuracy: 0.8741 - val_loss: 1.6501 - val_accuracy: 0.7893\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.4529 - accuracy: 0.8871 - val_loss: 1.6639 - val_accuracy: 0.7893\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 52s 207ms/step - loss: 0.3931 - accuracy: 0.8995 - val_loss: 1.6714 - val_accuracy: 0.7934\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 1165s 5s/step - loss: 0.3409 - accuracy: 0.9106 - val_loss: 1.6938 - val_accuracy: 0.7939\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.2972 - accuracy: 0.9205 - val_loss: 1.7114 - val_accuracy: 0.7935\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.2624 - accuracy: 0.9279 - val_loss: 1.7351 - val_accuracy: 0.7964\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 0.2321 - accuracy: 0.9355 - val_loss: 1.7432 - val_accuracy: 0.7981\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.2079 - accuracy: 0.9422 - val_loss: 1.7498 - val_accuracy: 0.7967\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 54s 218ms/step - loss: 0.1869 - accuracy: 0.9465 - val_loss: 1.7911 - val_accuracy: 0.7958\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.1726 - accuracy: 0.9501 - val_loss: 1.7811 - val_accuracy: 0.7981\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.1581 - accuracy: 0.9538 - val_loss: 1.7946 - val_accuracy: 0.7981\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.1473 - accuracy: 0.9556 - val_loss: 1.8083 - val_accuracy: 0.7959\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 55s 222ms/step - loss: 0.1366 - accuracy: 0.9588 - val_loss: 1.8197 - val_accuracy: 0.7982\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 0.1309 - accuracy: 0.9593 - val_loss: 1.8391 - val_accuracy: 0.7976\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.1257 - accuracy: 0.9609 - val_loss: 1.8336 - val_accuracy: 0.7984\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.1198 - accuracy: 0.9618 - val_loss: 1.8474 - val_accuracy: 0.7980\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Load and prepare the dataset\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, Attention, Concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load dataset (first 1000 lines)\n",
    "zip_path = keras.utils.get_file(\n",
    "    fname=\"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "data_dir = pathlib.Path(zip_path).parent / \"spa-eng\"\n",
    "text_file = data_dir / \"spa.txt\"\n",
    "with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().strip().split(\"\\n\")[:10000]\n",
    "sentence_pairs = [line.split(\"\\t\") for line in lines]\n",
    "\n",
    "# STEP 2: Preprocessing\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,多])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,多]+\", \" \", sentence)\n",
    "    return sentence.strip()\n",
    "\n",
    "cleaned_pairs = []\n",
    "for eng, spa in sentence_pairs:\n",
    "    eng = preprocess_sentence(eng)\n",
    "    spa = preprocess_sentence(spa)\n",
    "    spa = \"sos \" + spa + \" eos\"\n",
    "    cleaned_pairs.append((eng, spa))\n",
    "\n",
    "# STEP 3: Tokenization\n",
    "eng_texts, spa_texts = zip(*cleaned_pairs)\n",
    "\n",
    "eng_tokenizer = Tokenizer(filters='', lower=True)\n",
    "spa_tokenizer = Tokenizer(filters='', lower=True)\n",
    "eng_tokenizer.fit_on_texts(eng_texts)\n",
    "spa_tokenizer.fit_on_texts(spa_texts)\n",
    "reverse_spa_index = {v: k for k, v in spa_tokenizer.word_index.items()}\n",
    "\n",
    "\n",
    "eng_seq = eng_tokenizer.texts_to_sequences(eng_texts)\n",
    "spa_seq = spa_tokenizer.texts_to_sequences(spa_texts)\n",
    "\n",
    "max_eng_len = max(len(seq) for seq in eng_seq)\n",
    "max_spa_len = max(len(seq) for seq in spa_seq)\n",
    "\n",
    "encoder_input = pad_sequences(eng_seq, maxlen=max_eng_len, padding='post')\n",
    "decoder_input = pad_sequences([seq[:-1] for seq in spa_seq], maxlen=max_spa_len-1, padding='post')\n",
    "decoder_target = pad_sequences([seq[1:] for seq in spa_seq], maxlen=max_spa_len-1, padding='post')\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "spa_vocab_size = len(spa_tokenizer.word_index) + 1\n",
    "\n",
    "# STEP 4: Build the model (LSTM + Attention)\n",
    "embedding_dim = 128\n",
    "latent_dim = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,), name='encoder_input')\n",
    "encoder_emb = Embedding(eng_vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm, state_h, state_c = LSTM(latent_dim, return_sequences=True, return_state=True)(encoder_emb)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
    "decoder_emb = Embedding(spa_vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm, _, _ = LSTM(latent_dim, return_sequences=True, return_state=True)(decoder_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention\n",
    "attention = Attention()\n",
    "context_vector = attention([decoder_lstm, encoder_lstm])\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_lstm, context_vector])\n",
    "\n",
    "# Output layer\n",
    "decoder_outputs = Dense(spa_vocab_size, activation='softmax')(decoder_concat)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# STEP 5: Train\n",
    "model.fit([encoder_input, decoder_input], decoder_target,\n",
    "          batch_size=32,\n",
    "          epochs=25,\n",
    "          validation_split=0.2)\n",
    "\n",
    "model.save(\"final_nmt_model.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93443a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference setup\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "\n",
    "# Encoder inputs and outputs (from trained model)\n",
    "encoder_inf_inputs = model.get_layer('encoder_input').input\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.get_layer('lstm_2').output\n",
    "encoder_model = Model(encoder_inf_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
    "\n",
    "# Decoder inputs for inference\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_hidden_state_input = Input(shape=(None, 256))  # From encoder outputs\n",
    "\n",
    "decoder_inf_inputs = Input(shape=(1,))\n",
    "\n",
    "# Use correct embedding and LSTM layer names\n",
    "dec_emb_layer = model.get_layer('embedding_3')\n",
    "decoder_lstm_layer = model.get_layer('lstm_3')\n",
    "attention_layer = model.get_layer('attention_1')\n",
    "concat_layer = model.get_layer('concatenate_1')\n",
    "dense_layer = model.get_layer('dense_1')\n",
    "\n",
    "# Embedding\n",
    "dec_emb_inf = dec_emb_layer(decoder_inf_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_outputs, state_h, state_c = decoder_lstm_layer(\n",
    "    dec_emb_inf, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
    ")\n",
    "\n",
    "# Attention\n",
    "attn_out_inf = attention_layer([decoder_outputs, decoder_hidden_state_input])\n",
    "decoder_concat_inf = concat_layer([decoder_outputs, attn_out_inf])\n",
    "\n",
    "# Final output layer\n",
    "decoder_outputs_final = dense_layer(decoder_concat_inf)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_model = Model(\n",
    "    [decoder_inf_inputs, decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs_final, state_h, state_c]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5393ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    enc_outs, h, c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.array([[spa_tokenizer.word_index['sos']]])\n",
    "    decoded_sentence = ''\n",
    "    stop_condition = False\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq, enc_outs, h, c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_spa_index.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_word == 'eos' or len(decoded_sentence.split()) > max_spa_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a681c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "English: i love you .\n",
      "Spanish: te amo .\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "English: slowly\n",
      "Spanish: termina de aqu .\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "English: what are you doing ?\n",
      "Spanish: 多 qu lo sabes ?\n"
     ]
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
    "    padded = pad_sequences(seq, maxlen=max_eng_len, padding='post')\n",
    "    translation = decode_sequence(padded)\n",
    "    print(f\"English: {sentence}\")\n",
    "    print(f\"Spanish: {translation}\")\n",
    "\n",
    "translate(\"I love you.\")\n",
    "translate(\"Slowly\")\n",
    "translate(\"What are you doing?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14d172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Save model\n",
    "model.save(\"spanish_translation_model.keras\")\n",
    "\n",
    "# Save tokenizers\n",
    "with open(\"eng_tokenizer.json\", \"w\") as f:\n",
    "    f.write(eng_tokenizer.to_json())\n",
    "\n",
    "with open(\"spa_tokenizer.json\", \"w\") as f:\n",
    "    f.write(spa_tokenizer.to_json())\n",
    "\n",
    "\n",
    "# Save reverse index\n",
    "reverse_spa_index = {v: k for k, v in spa_tokenizer.word_index.items()}\n",
    "with open(\"reverse_spa_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reverse_spa_index, f)\n",
    "\n",
    "# Save max sequence lengths\n",
    "with open(\"seq_lengths.json\", \"w\") as f:\n",
    "    json.dump({\"max_eng_len\": max_eng_len, \"max_spa_len\": max_spa_len}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c1bffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realtime_eng_to_spa(duration=10, chunk=1024):\n",
    "    \"\"\"\n",
    "    Records English speech in real-time, displays recognized text,\n",
    "    translates to Spanish, and reads it aloud.\n",
    "    \"\"\"\n",
    "    q = queue.Queue()\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    def callback(indata, frames, time_info, status):\n",
    "        if status:\n",
    "            print(status, flush=True)\n",
    "        q.put(indata.copy())\n",
    "\n",
    "    print(\"Start speaking (English)...\")\n",
    "    with sd.InputStream(channels=1, samplerate=16000, blocksize=chunk, callback=callback):\n",
    "        audio_buffer = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        while time.time() - start_time < duration:\n",
    "            try:\n",
    "                data = q.get(timeout=1)\n",
    "                audio_buffer.append(data)\n",
    "\n",
    "                # Process every ~1 second of audio\n",
    "                if len(audio_buffer) * chunk / 16000 >= 1.0:\n",
    "                    audio_chunk = np.concatenate(audio_buffer, axis=0).flatten()\n",
    "                    audio_chunk = (audio_chunk * 32767).astype('int16')\n",
    "                    audio_obj = sr.AudioData(audio_chunk.tobytes(), 16000, 2)\n",
    "                    try:\n",
    "                        text = recognizer.recognize_google(audio_obj, language='en-US')\n",
    "                        if text:\n",
    "                            print(\"You said:\", text)\n",
    "                            # Translate\n",
    "                            seq = eng_tokenizer.texts_to_sequences([preprocess_sentence(text)])\n",
    "                            padded = pad_sequences(seq, maxlen=max_eng_len, padding='post')\n",
    "                            translation = decode_sequence(padded)\n",
    "                            print(\"Translation (Spanish):\", translation)\n",
    "                            speak_text(translation)\n",
    "                    except sr.UnknownValueError:\n",
    "                        pass\n",
    "                    # Clear buffer after processing\n",
    "                    audio_buffer = []\n",
    "\n",
    "            except queue.Empty:\n",
    "                pass\n",
    "\n",
    "    print(\"Recording stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6935abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start speaking (English)...\n",
      "You said: hi how are you\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Translation (Spanish): 多 qu tal ah ?\n",
      "You said: what are you doing\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Translation (Spanish): tienes por mo .\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# RUN REAL-TIME ENGLISH -> SPANISH TRANSLATOR\n",
    "# ==========================\n",
    "\n",
    "# duration=10 means it will record for 10 seconds max\n",
    "realtime_eng_to_spa(duration=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d92dac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'googletrans' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'googletrans'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start speaking (Spanish)...\n",
      "You said (Spanish): hola\n",
      "Translation (English): hello\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Spanish -> English Live Translator (Demo using Google Translate)\n",
    "# ==========================\n",
    "\n",
    "!pip install SpeechRecognition sounddevice pyttsx3 googletrans==4.0.0-rc1 --quiet\n",
    "\n",
    "import sounddevice as sd\n",
    "import queue\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "# Initialize speech recognizer, translator, and TTS\n",
    "recognizer = sr.Recognizer()\n",
    "translator = Translator()\n",
    "tts = pyttsx3.init()\n",
    "\n",
    "def speak_text(text):\n",
    "    tts.say(text)\n",
    "    tts.runAndWait()\n",
    "\n",
    "def realtime_spa_to_eng(duration=10, chunk=1024):\n",
    "    \"\"\"\n",
    "    Records Spanish speech in real-time, displays recognized text,\n",
    "    translates to English using Google Translate, and reads it aloud.\n",
    "    \"\"\"\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def callback(indata, frames, time_info, status):\n",
    "        if status:\n",
    "            print(status, flush=True)\n",
    "        q.put(indata.copy())\n",
    "\n",
    "    print(\"Start speaking (Spanish)...\")\n",
    "    with sd.InputStream(channels=1, samplerate=16000, blocksize=chunk, callback=callback):\n",
    "        audio_buffer = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        while time.time() - start_time < duration:\n",
    "            try:\n",
    "                data = q.get(timeout=1)\n",
    "                audio_buffer.append(data)\n",
    "\n",
    "                # Process every ~1 second of audio\n",
    "                if len(audio_buffer) * chunk / 16000 >= 1.0:\n",
    "                    audio_chunk = np.concatenate(audio_buffer, axis=0).flatten()\n",
    "                    audio_chunk = (audio_chunk * 32767).astype('int16')\n",
    "                    audio_obj = sr.AudioData(audio_chunk.tobytes(), 16000, 2)\n",
    "                    try:\n",
    "                        # Recognize Spanish speech\n",
    "                        text = recognizer.recognize_google(audio_obj, language='es-ES')\n",
    "                        if text:\n",
    "                            print(\"You said (Spanish):\", text)\n",
    "                            # Translate to English\n",
    "                            translation = translator.translate(text, src='es', dest='en').text\n",
    "                            print(\"Translation (English):\", translation)\n",
    "                            speak_text(translation)\n",
    "                    except sr.UnknownValueError:\n",
    "                        pass\n",
    "                    # Clear buffer after processing\n",
    "                    audio_buffer = []\n",
    "\n",
    "            except queue.Empty:\n",
    "                pass\n",
    "\n",
    "    print(\"Recording stopped.\")\n",
    "\n",
    "# ==========================\n",
    "# Example usage: record 10 seconds\n",
    "# ==========================\n",
    "realtime_spa_to_eng(duration=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
